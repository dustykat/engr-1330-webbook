<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        
        <link rel="shortcut icon" href="../../../img/favicon.ico">
        <title>Lab20 - ENGR 1330</title>
        <link href="../../../css/bootstrap-custom.min.css" rel="stylesheet">
        <link href="../../../css/font-awesome.min.css" rel="stylesheet">
        <link href="../../../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">

        <script src="../../../js/jquery-1.10.2.min.js" defer></script>
        <script src="../../../js/bootstrap-3.0.3.min.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/python.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script> 
    </head>

    <body>

        <div class="navbar navbar-default navbar-fixed-top" role="navigation">
            <div class="container">

                <!-- Collapsed navigation -->
                <div class="navbar-header">
                    <!-- Expander button -->
                    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                        <span class="sr-only">Toggle navigation</span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>
                    <a class="navbar-brand" href="../../..">ENGR 1330</a>
                </div>

                <!-- Expanded navigation -->
                <div class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li >
                                <a href="../../..">Home</a>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="dropdown-toggle" data-toggle="dropdown">Intro <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li >
    <a href="../../../1-Lessons/Lesson00/lesson0/">Computational Thinking and Data Science</a>
</li>
                                    
<li >
    <a href="../../../1-Lessons/Lesson01/lesson1/">Problem Solving with Computational Thinking</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="dropdown-toggle" data-toggle="dropdown">Python Scripting <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li >
    <a href="../../../1-Lessons/Lesson02/lesson2/">Simple Computation</a>
</li>
                                    
<li >
    <a href="../../../1-Lessons/Lesson03/lesson3/">Data Structures and the MATH package</a>
</li>
                                    
<li >
    <a href="../../../1-Lessons/Lesson04/lesson4/">Program Control Structures</a>
</li>
                                    
<li >
    <a href="../../../lesson0/lesson0/">External Functions and Modules</a>
</li>
                                    
<li >
    <a href="../../../lesson0/lesson0/">Engineering and Scientific Data Files</a>
</li>
                                    
<li >
    <a href="../../../1-Lessons/Lesson07/lesson6/">Computational Linear Algebra using NUMPY</a>
</li>
                                    
<li >
    <a href="../../../1-Lessons/Lesson08/lesson7/">Database Query and Manipulation using PANDAS</a>
</li>
                                    
<li >
    <a href="../../../1-Lessons/Lesson09/lesson8/">Visual Display of Data using MATPLOTLIB</a>
</li>
                                    
<li >
    <a href="../../../1-Lessons/Lesson10/lesson10/">Implicit Equations</a>
</li>
                                    
<li >
    <a href="../../../1-Lessons/Lesson11/lesson11/">Interpolation and Integration</a>
</li>
                                    
<li >
    <a href="../../../1-Lessons/Lesson12/lesson12/">Linear Equation Systems</a>
</li>
                                    
<li >
    <a href="../../../1-Lessons/Lesson13/lesson13/">Non-Linear Equation Systems</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="dropdown-toggle" data-toggle="dropdown">Models & Decisions <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li >
    <a href="../../../lesson0/lesson0/">Statistical Data Modeling</a>
</li>
                                    
<li >
    <a href="../../../lesson0/lesson0/">Randomness and Probability</a>
</li>
                                    
<li >
    <a href="../../../1-Lessons/Lesson15/lesson15/">Descriptive Statistics</a>
</li>
                                    
<li >
    <a href="../../../lesson0/lesson0/">Distribution Models</a>
</li>
                                    
<li >
    <a href="../../../1-Lessons/Lesson17/lesson17/">Probability Estimation Modeling</a>
</li>
                                    
<li >
    <a href="../../../lesson0/lesson0/">Hypothesis Testing</a>
</li>
                                    
<li >
    <a href="../../../lesson0/lesson0/">Experimental Design (A/B Testing)</a>
</li>
                                    
<li >
    <a href="../../../lesson0/lesson0/">Interval Estimates</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="dropdown-toggle" data-toggle="dropdown">Prediction <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li >
    <a href="../../../lesson0/lesson0/">Fitting Models to Observations</a>
</li>
                                    
<li >
    <a href="../../../lesson0/lesson0/">Least Squares (Regression) Model Fitting</a>
</li>
                                    
<li >
    <a href="../../../lesson0/lesson0/">Model Quality</a>
</li>
                                    
<li >
    <a href="../../../lesson0/lesson0/">Estimating Probability/Quantile Regression</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="dropdown-toggle" data-toggle="dropdown">Classification <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li >
    <a href="../../../lesson0/lesson0/">Introduction</a>
</li>
                                    
<li >
    <a href="../../../lesson0/lesson0/">Types</a>
</li>
                                    
<li >
    <a href="../../../lesson0/lesson0/">K Nearest Neighbor</a>
</li>
                                    
<li >
    <a href="../../../lesson0/lesson0/">Engine Update</a>
</li>
                                </ul>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav navbar-right">
                        <li>
                            <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
                <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
        <li class="main active"><a href="#laboratory-20-on-precognition-and-other-sins-of-the-human-brain">Laboratory 20: On Precognition and Other Sins of the Human Brain </a></li>
            <li><a href="#full-name">Full name:</a></li>
            <li><a href="#r">R#:</a></li>
            <li><a href="#title-of-the-notebook">Title of the notebook</a></li>
            <li><a href="#date">Date:</a></li>
            <li><a href="#-">---</a></li>
        <li class="main "><a href="#3-problem-2-8-pts">3 Problem 2 (8 pts)</a></li>
            <li><a href="#-_1">---</a></li>
            <li><a href="#so-how-do-we-estimate-and">So, how do we estimate Œ± and Œ≤? </a></li>
            <li><a href="#goodness-of-fit">Goodness-of-Fit </a></li>
            <li><a href="#exercise-linear-regression-yea-or-nay">Exercise: Linear Regression - Yea or Nay </a></li>
    </ul>
</div></div>
                <div class="col-md-9" role="main">

<p><strong>Download</strong> (right-click, save target as ...) this page as a jupyterlab notebook from: (LINK NEEDS FIXING!)</p>
<p><a href="https://atomickitty.ddns.net:8000/user/sensei/files/engr-1330-webroot/engr-1330-webbook/ctds-psuedocourse/docs/8-Labs/Lab8/Lab9_Dev.ipynb?_xsrf=2%7C1b4d47c3%7C0c3aca0c53606a3f4b71c448b09296ae%7C1623531240">Lab20</a></p>
<hr />
<h1 id="laboratory-20-on-precognition-and-other-sins-of-the-human-brain"><font color=darkred>Laboratory 20: On Precognition and Other Sins of the Human Brain </font></h1>
<pre><code class="python"># Preamble script block to identify host, user, and kernel
import sys
! hostname
! whoami
print(sys.executable)
print(sys.version)
print(sys.version_info)
</code></pre>

<pre><code>DESKTOP-EH6HD63
desktop-eh6hd63\farha
C:\Users\Farha\Anaconda3\python.exe
3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)]
sys.version_info(major=3, minor=7, micro=4, releaselevel='final', serial=0)
</code></pre>
<h2 id="full-name">Full name:</h2>
<h2 id="r">R#:</h2>
<h2 id="title-of-the-notebook">Title of the notebook</h2>
<h2 id="date">Date:</h2>
<p><img alt="" src="https://i.pinimg.com/originals/5f/d5/58/5fd558f8b7a4f9e2138709cbe63c7052.gif" /> <br></p>
<h4 id="the-human-brain-is-amazing-and-mysterious-in-many-ways-have-a-look-at-these-sequences-you-with-the-assistance-of-your-brain-can-guess-the-next-item-in-each-sequence-right">The human brain is amazing and mysterious in many ways. Have a look at these sequences. You, with the assistance of your brain, can guess the next item in each sequence, right? <br></h4>
<ul>
<li>A,B,C,D,E, ____ ?</li>
<li>5,10,15,20,25, ____ ?</li>
<li>2,4,8,16,32 ____ ?</li>
<li>0,1,1,2,3, ____ ?</li>
<li>1, 11, 21, 1211,111221, ____ ?</li>
</ul>
<p><img alt="" src="https://3.bp.blogspot.com/-cZXhOB-3MCI/U8zCNevhDUI/AAAAAAAABd4/HK-3xKM_SlQ/s1600/The+Golden+Ratio+Spiral+.jpg" /> <br>
<img alt="" src="https://i.pinimg.com/originals/80/50/e5/8050e54fd2b4ceb033c8b98586a12972.jpg" /> <br>
<img alt="" src="https://eternallivinghome.files.wordpress.com/2019/11/image-4.png?w=409" /> <br>
<img alt="" src="https://eternallivinghome.files.wordpress.com/2019/11/image-2.png" /> <br>
<img alt="" src="https://eternallivinghome.files.wordpress.com/2019/11/image-1.png?w=414" /> <br>
<img alt="" src="https://eternallivinghome.files.wordpress.com/2019/11/image-6.png?w=507" /> <br>
<img alt="" src="https://eternallivinghome.files.wordpress.com/2019/11/image-20.png?w=506" /> <br>
<img alt="" src="https://eternallivinghome.files.wordpress.com/2019/11/image-8.png" /> <br>
<img alt="" src="https://eternallivinghome.files.wordpress.com/2019/11/image-22.png?w=1024" /> <br></p>
<h4 id="but-how-does-our-brain-do-this-how-do-we-guess-predict-the-next-step-is-it-that-there-is-only-one-possible-option-is-it-that-we-have-the-previous-items-or-is-it-the-relationship-between-the-items">But how does our brain do this? How do we 'guess | predict' the next step? Is it that there is only one possible option? is it that we have the previous items? or is it the relationship between the items?<br></h4>
<h4 id="what-if-we-have-more-than-a-single-sequence-maybe-two-sets-of-numbers-how-can-we-predict-the-next-item-in-a-situation-like-that">What if we have more than a single sequence? Maybe two sets of numbers? How can we predict the next "item" in a situation like that? <br></h4>
<p><img alt="" src="https://media.makeameme.org/created/ring-that-bell-ws9mb9.jpg" /> <br></p>
<h4 id="blue-points-red-line-fit-does-it-ring-any-bells">Blue Points? Red Line? Fit? Does it ring any bells? <br></h4>
<p><img alt="" src="https://38.media.tumblr.com/d51a8aa16dd9e4d40b718b1af803b9be/tumblr_n9kohlL3AR1tofduqo1_500.gif" /> <br></p>
<h2 id="-">---</h2>
<hr />
<h1 id="3-problem-2-8-pts">3 Problem 2 (8 pts)</h1>
<p>The table below contains some experimental observations.</p>
<table>
<thead>
<tr>
<th align="right">Elapsed Time (s)</th>
<th align="right">Speed (m/s)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr>
<td align="right">1.0</td>
<td align="right">3</td>
</tr>
<tr>
<td align="right">2.0</td>
<td align="right">7</td>
</tr>
<tr>
<td align="right">3.0</td>
<td align="right">12</td>
</tr>
<tr>
<td align="right">4.0</td>
<td align="right">20</td>
</tr>
<tr>
<td align="right">5.0</td>
<td align="right">30</td>
</tr>
<tr>
<td align="right">6.0</td>
<td align="right">45.6</td>
</tr>
<tr>
<td align="right">7.0</td>
<td align="right">60.3</td>
</tr>
<tr>
<td align="right">8.0</td>
<td align="right">77.7</td>
</tr>
<tr>
<td align="right">9.0</td>
<td align="right">97.3</td>
</tr>
<tr>
<td align="right">10.0</td>
<td align="right">121.1</td>
</tr>
</tbody>
</table>
<ol>
<li>Plot the speed vs time (speed on y-axis, time on x-axis) using a scatter plot.  Use blue markers. </li>
<li>Plot a red line on the scatterplot based on the linear model <script type="math/tex">f(x) = mx + b</script>
</li>
<li>By trial-and-error find values of <script type="math/tex">m</script> and <script type="math/tex">b</script> that provide a good visual fit (i.e. makes the red line explain the blue markers).</li>
<li>Using this data model estimate the speed at <script type="math/tex">t = 15~\texttt{sec.}</script>
</li>
</ol>
<hr />
<h2 id="-_1">---</h2>
<p><img alt="" src="https://media1.tenor.com/images/e43d77dca4b2096cad8226e150ae072f/tenor.gif?itemid=17107650" /> <br></p>
<h3 id="lets-go-over-some-important-terminology">Let's go over some important terminology:</h3>
<pre><code>Linear Regression:
a basic predictive analytics technique that uses historical data to predict an output variable.

The Predictor variable (input):
the variable(s) that help predict the value of the output variable. It is commonly referred to as X.

The Output variable:
the variable that we want to predict. It is commonly referred to as Y.
</code></pre>
<h4 id="to-estimate-y-using-linear-regression-we-assume-the-equation-ye-x">To estimate Y using linear regression, we assume the equation: <script type="math/tex">Ye = Œ≤X + Œ±</script>
</h4>
<p><em>where Y‚Çë is the estimated or predicted value of Y based on our linear equation.</em> <br></p>
<h4 id="our-goal-is-to-find-statistically-significant-values-of-the-parameters-and-that-minimise-the-difference-between-y-and-ye-if-we-are-able-to-determine-the-optimum-values-of-these-two-parameters-then-we-will-have-the-line-of-best-fit-that-we-can-use-to-predict-the-values-of-y-given-the-value-of-x">Our goal is to find statistically significant values of the parameters Œ± and Œ≤ that minimise the difference between Y and Y‚Çë. If we are able to determine the optimum values of these two parameters, then we will have the line of best fit that we can use to predict the values of Y, given the value of X. <br></h4>
<h2 id="so-how-do-we-estimate-and">So, how do we estimate Œ± and Œ≤? <br></h2>
<p><img alt="" src="https://media3.giphy.com/media/EijsQdawZkiqY/200.gif" /> <br></p>
<h4 id="we-can-use-a-method-called-ordinary-least-squares-ols">We can use a method called Ordinary Least Squares (OLS). <br></h4>
<p><img alt="" src="https://miro.medium.com/max/338/1*VVA0rF6MWXcw1JmRNFA87g.png" /> <br></p>
<h4 id="the-objective-of-the-least-squares-method-is-to-find-values-of-and-that-minimise-the-sum-of-the-squared-difference-between-y-and-ye-distance-between-the-linear-fit-and-the-observed-points-we-will-not-go-through-the-derivation-here-but-using-calculus-we-can-show-that-the-values-of-the-unknown-parameters-are-as-follows">The objective of the least squares method is to find values of Œ± and Œ≤ that minimise the sum of the squared difference between Y and Y‚Çë (distance between the linear fit and the observed points). We will not go through the derivation here, but using calculus we can show that the values of the unknown parameters are as follows: <br></h4>
<p><img alt="" src="https://miro.medium.com/max/222/0*gR-W7RFar9ijxwAa" /> <br></p>
<h4 id="where-x-is-the-mean-of-x-values-and-y-is-the-mean-of-y-values-is-simply-the-covariance-of-x-and-y-covx-y-devided-by-the-variance-of-x-varx">where XÃÑ is the mean of X values and »≤ is the mean of Y values. Œ≤ is simply the covariance of X and Y (Cov(X, Y)  devided by the variance of X (Var(X)). <br></h4>
<pre><code>Covariance:
In probability theory and statistics, covariance is a measure of the joint variability of two random variables. If the greater values of one variable mainly correspond with the greater values of the other variable, and the same holds for the lesser values, (i.e., the variables tend to show similar behavior), the covariance is positive. In the opposite case, when the greater values of one variable mainly correspond to the lesser values of the other, (i.e., the variables tend to show opposite behavior), the covariance is negative. The sign of the covariance therefore shows the tendency in the linear relationship between the variables. The magnitude of the covariance is not easy to interpret because it is not normalized and hence depends on the magnitudes of the variables. The normalized version of the covariance, the correlation coefficient, however, shows by its magnitude the strength of the linear relation.
</code></pre>
<p><img alt="" src="https://www.wallstreetmojo.com/wp-content/uploads/2019/03/Covariance-Formula.jpg" /> <br>
<img alt="" src="https://media.geeksforgeeks.org/wp-content/uploads/Correl.png" /> <br></p>
<pre><code>The Correlation Coefficient:
Correlation coefficients are used in statistics to measure how strong a relationship is between two variables. There are several types of correlation coefficient, but the most popular is Pearson‚Äôs. Pearson‚Äôs correlation (also called Pearson‚Äôs R) is a correlation coefficient commonly used in linear regression.Correlation coefficient formulas are used to find how strong a relationship is between data. The formulat for Pearson‚Äôs R:
</code></pre>
<p><img alt="" src="https://www.statisticshowto.com/wp-content/uploads/2012/10/pearson.gif" /> <br></p>
<pre><code>The formulas return a value between -1 and 1, where:
</code></pre>
<p><img alt="" src="https://www.statisticshowto.com/wp-content/uploads/2012/10/pearson-2-small.png" /> <br></p>
<pre><code>1 : A correlation coefficient of 1 means that for every positive increase in one variable, there is a positive increase of a fixed proportion in the other. For example, shoe sizes go up in (almost) perfect correlation with foot length.
-1: A correlation coefficient of -1 means that for every positive increase in one variable, there is a negative decrease of a fixed proportion in the other. For example, the amount of gas in a tank decreases in (almost) perfect correlation with speed.
0 : Zero means that for every increase, there isn‚Äôt a positive or negative increase. The two just aren‚Äôt related.
</code></pre>
<hr />
<h3 id="example-lets-have-a-look-at-the-problem-1-from-exam-ii">Example: Let's have a look at the Problem  1 from Exam II<br></h3>
<h4 id="we-had-a-table-of-recoded-times-and-speeds-from-some-experimental-observations">We had a table of recoded times and speeds from some experimental observations:</h4>
<table>
<thead>
<tr>
<th align="right">Elapsed Time (s)</th>
<th align="right">Speed (m/s)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr>
<td align="right">1.0</td>
<td align="right">3</td>
</tr>
<tr>
<td align="right">2.0</td>
<td align="right">7</td>
</tr>
<tr>
<td align="right">3.0</td>
<td align="right">12</td>
</tr>
<tr>
<td align="right">4.0</td>
<td align="right">20</td>
</tr>
<tr>
<td align="right">5.0</td>
<td align="right">30</td>
</tr>
<tr>
<td align="right">6.0</td>
<td align="right">45.6</td>
</tr>
<tr>
<td align="right">7.0</td>
<td align="right">60.3</td>
</tr>
<tr>
<td align="right">8.0</td>
<td align="right">77.7</td>
</tr>
<tr>
<td align="right">9.0</td>
<td align="right">97.3</td>
</tr>
<tr>
<td align="right">10.0</td>
<td align="right">121.1</td>
</tr>
</tbody>
</table>
<h4 id="first-lets-create-a-dataframe">First let's create a dataframe:</h4>
<pre><code class="python"># Load the necessary packages
import numpy as np
import pandas as pd
import statistics 
from matplotlib import pyplot as plt

# Create a dataframe:
time = [0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]
speed = [0, 3, 7, 12, 20, 30, 45.6, 60.3, 77.7, 97.3, 121.2]
data = pd.DataFrame({'Time':time, 'Speed':speed})
data
</code></pre>

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Time</th>
      <th>Speed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.0</td>
      <td>3.0</td>
    </tr>
    <tr>
      <td>2</td>
      <td>2.0</td>
      <td>7.0</td>
    </tr>
    <tr>
      <td>3</td>
      <td>3.0</td>
      <td>12.0</td>
    </tr>
    <tr>
      <td>4</td>
      <td>4.0</td>
      <td>20.0</td>
    </tr>
    <tr>
      <td>5</td>
      <td>5.0</td>
      <td>30.0</td>
    </tr>
    <tr>
      <td>6</td>
      <td>6.0</td>
      <td>45.6</td>
    </tr>
    <tr>
      <td>7</td>
      <td>7.0</td>
      <td>60.3</td>
    </tr>
    <tr>
      <td>8</td>
      <td>8.0</td>
      <td>77.7</td>
    </tr>
    <tr>
      <td>9</td>
      <td>9.0</td>
      <td>97.3</td>
    </tr>
    <tr>
      <td>10</td>
      <td>10.0</td>
      <td>121.2</td>
    </tr>
  </tbody>
</table>
</div>

<h4 id="now-lets-explore-the-data">Now, let's explore the data:</h4>
<pre><code class="python">data.describe()
</code></pre>

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Time</th>
      <th>Speed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>count</td>
      <td>11.000000</td>
      <td>11.000000</td>
    </tr>
    <tr>
      <td>mean</td>
      <td>5.000000</td>
      <td>43.100000</td>
    </tr>
    <tr>
      <td>std</td>
      <td>3.316625</td>
      <td>41.204077</td>
    </tr>
    <tr>
      <td>min</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <td>25%</td>
      <td>2.500000</td>
      <td>9.500000</td>
    </tr>
    <tr>
      <td>50%</td>
      <td>5.000000</td>
      <td>30.000000</td>
    </tr>
    <tr>
      <td>75%</td>
      <td>7.500000</td>
      <td>69.000000</td>
    </tr>
    <tr>
      <td>max</td>
      <td>10.000000</td>
      <td>121.200000</td>
    </tr>
  </tbody>
</table>
</div>

<pre><code class="python">time_var = statistics.variance(time)
speed_var = statistics.variance(speed)

print(&quot;Variance of recorded times is &quot;,time_var)
print(&quot;Variance of recorded speed is &quot;,speed_var)
</code></pre>

<pre><code>Variance of recorded times is  11.0
Variance of recorded speed is  1697.7759999999998
</code></pre>
<h4 id="is-there-a-relationship-based-on-covariance-correlation-between-time-and-speed">Is there a relationship ( based on covariance, correlation) between time and speed?</h4>
<pre><code class="python"># To find the covariance  
data.cov() 
</code></pre>

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Time</th>
      <th>Speed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Time</td>
      <td>11.00</td>
      <td>131.750</td>
    </tr>
    <tr>
      <td>Speed</td>
      <td>131.75</td>
      <td>1697.776</td>
    </tr>
  </tbody>
</table>
</div>

<pre><code class="python"># To find the correlation among the columns 
# using pearson method 
data.corr(method ='pearson') 
</code></pre>

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Time</th>
      <th>Speed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Time</td>
      <td>1.000000</td>
      <td>0.964082</td>
    </tr>
    <tr>
      <td>Speed</td>
      <td>0.964082</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>

<h4 id="lets-do-linear-regression-with-primitive-python">Let's do linear regression with primitive Python:</h4>
<h4 id="to-estimate-y-using-the-ols-method-we-need-to-calculate-xmean-and-ymean-the-covariance-of-x-and-y-xycov-and-the-variance-of-x-xvar-before-we-can-determine-the-values-for-alpha-and-beta-in-our-case-x-is-time-and-y-is-speed">To estimate "y" using the OLS method, we need to calculate "xmean" and "ymean", the covariance of X and y ("xycov"), and the variance of X ("xvar") before we can determine the values for alpha and beta. In our case, X is time and y is Speed.</h4>
<pre><code class="python"># Calculate the mean of X and y
xmean = np.mean(time)
ymean = np.mean(speed)

# Calculate the terms needed for the numator and denominator of beta
data['xycov'] = (data['Time'] - xmean) * (data['Speed'] - ymean)
data['xvar'] = (data['Time'] - xmean)**2

# Calculate beta and alpha
beta = data['xycov'].sum() / data['xvar'].sum()
alpha = ymean - (beta * xmean)
print(f'alpha = {alpha}')
print(f'beta = {beta}')

</code></pre>

<pre><code>alpha = -16.78636363636363
beta = 11.977272727272727
</code></pre>
<h4 id="we-now-have-an-estimate-for-alpha-and-beta-our-model-can-be-written-as-ye-11977-x-16786-and-we-can-make-predictions">We now have an estimate for alpha and beta! Our model can be written as Y‚Çë = 11.977 X -16.786, and we can make predictions:</h4>
<pre><code class="python">X = np.array(time)

ypred = alpha + beta * X
print(ypred)
</code></pre>

<pre><code>[-16.78636364  -4.80909091   7.16818182  19.14545455  31.12272727
  43.1         55.07727273  67.05454545  79.03181818  91.00909091
 102.98636364]
</code></pre>
<h4 id="lets-plot-our-prediction-ypred-against-the-actual-values-of-y-to-get-a-better-visual-understanding-of-our-model">Let‚Äôs plot our prediction ypred against the actual values of y, to get a better visual understanding of our model:</h4>
<pre><code class="python"># Plot regression against actual data
plt.figure(figsize=(12, 6))
plt.plot(X, ypred, color=&quot;red&quot;)     # regression line
plt.plot(time, speed, 'ro', color=&quot;blue&quot;)   # scatter plot showing actual data
plt.title('Actual vs Predicted')
plt.xlabel('Time (s)')
plt.ylabel('Speed (m/s)')

plt.show()
</code></pre>

<p><img alt="png" src="output_21_0.png" /></p>
<h4 id="the-red-line-is-our-line-of-best-fit-ye-11977-x-16786-we-can-see-from-this-graph-that-there-is-a-positive-linear-relationship-between-x-and-y-using-our-model-we-can-predict-y-from-any-values-of-x">The red line is our line of best fit, Y‚Çë = 11.977 X -16.786. We can see from this graph that there is a positive linear relationship between X and y. Using our model, we can predict y from any values of X! <br></h4>
<h4 id="for-example-if-we-had-a-value-x-20-we-can-predict-that">For example, if we had a value X = 20, we can predict that:</h4>
<pre><code class="python">ypred_20 = alpha + beta * 20
print(ypred_20)
</code></pre>

<pre><code>222.7590909090909
</code></pre>
<h4 id="linear-regression-with-statsmodels">Linear Regression with statsmodels:</h4>
<h4 id="first-we-use-statsmodels-ols-function-to-initialise-our-simple-linear-regression-model-this-takes-the-formula-y-x-where-x-is-the-predictor-variable-time-and-y-is-the-output-variable-speed-then-we-fit-the-model-by-calling-the-ols-objects-fit-method">First, we use statsmodels‚Äô ols function to initialise our simple linear regression model. This takes the formula y ~ X, where X is the predictor variable (Time) and y is the output variable (Speed). Then, we fit the model by calling the OLS object‚Äôs fit() method.</h4>
<pre><code class="python">import statsmodels.formula.api as smf

# Initialise and fit linear regression model using `statsmodels`
model = smf.ols('Speed ~ Time', data=data)
model = model.fit()
</code></pre>

<h4 id="we-no-longer-have-to-calculate-alpha-and-beta-ourselves-as-this-method-does-it-automatically-for-us-calling-modelparams-will-show-us-the-models-parameters">We no longer have to calculate alpha and beta ourselves as this method does it automatically for us! Calling model.params will show us the model‚Äôs parameters:</h4>
<pre><code class="python">model.params
</code></pre>

<pre><code>Intercept   -16.786364
Time         11.977273
dtype: float64
</code></pre>
<h4 id="in-the-notation-that-we-have-been-using-is-the-intercept-and-is-the-slope-ie-16786364-and-11977273">In the notation that we have been using, Œ± is the intercept and Œ≤ is the slope i.e. Œ± =-16.786364 and Œ≤ = 11.977273.</h4>
<pre><code class="python"># Predict values
speed_pred = model.predict()

# Plot regression against actual data
plt.figure(figsize=(12, 6))
plt.plot(data['Time'], data['Speed'], 'o')           # scatter plot showing actual data
plt.plot(data['Time'], speed_pred, 'r', linewidth=2)   # regression line
plt.xlabel('Time (s)')
plt.ylabel('Speed (m/s)')
plt.title('model vs observed')

plt.show()
</code></pre>

<p><img alt="png" src="output_29_0.png" /></p>
<h4 id="how-good-do-you-feel-about-this-predictive-model-will-you-trust-it">How good do you feel about this predictive model? Will you trust it?</h4>
<hr />
<h3 id="example-advertising-and-sells">Example: Advertising and Sells! <br></h3>
<h4 id="this-is-a-classic-regression-problem-we-have-a-dataset-of-the-spendings-on-tv-radio-and-newspaper-advertisements-and-number-of-sales-for-a-specific-product-we-are-interested-in-exploring-the-relationship-between-these-parameters-and-answering-the-following-questions">This is a classic regression problem. we have a dataset of the spendings on TV, Radio, and Newspaper advertisements and number of sales for a specific product. We are interested in exploring the relationship between these parameters and answering the following questions:</h4>
<ul>
<li>Can TV advertising spending predict the number of sales for the product?</li>
<li>Can Radio advertising spending predict the number of sales for the product?</li>
<li>Can Newspaper advertising spending predict the number of sales for the product?</li>
<li>Can we use the three of them to predict the number of sales for the product? | Multiple Linear Regression Model</li>
<li>Which parameter is a better predictor of the number of sales for the product?</li>
</ul>
<pre><code class="python"># Import and display first rows of the advertising dataset
df = pd.read_csv('advertising.csv')
df.head()
</code></pre>

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>TV</th>
      <th>Radio</th>
      <th>Newspaper</th>
      <th>Sales</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>230.1</td>
      <td>37.8</td>
      <td>69.2</td>
      <td>22.1</td>
    </tr>
    <tr>
      <td>1</td>
      <td>44.5</td>
      <td>39.3</td>
      <td>45.1</td>
      <td>10.4</td>
    </tr>
    <tr>
      <td>2</td>
      <td>17.2</td>
      <td>45.9</td>
      <td>69.3</td>
      <td>9.3</td>
    </tr>
    <tr>
      <td>3</td>
      <td>151.5</td>
      <td>41.3</td>
      <td>58.5</td>
      <td>18.5</td>
    </tr>
    <tr>
      <td>4</td>
      <td>180.8</td>
      <td>10.8</td>
      <td>58.4</td>
      <td>12.9</td>
    </tr>
  </tbody>
</table>
</div>

<pre><code class="python"># Describe the df
df.describe()
</code></pre>

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>TV</th>
      <th>Radio</th>
      <th>Newspaper</th>
      <th>Sales</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>count</td>
      <td>200.000000</td>
      <td>200.000000</td>
      <td>200.000000</td>
      <td>200.000000</td>
    </tr>
    <tr>
      <td>mean</td>
      <td>147.042500</td>
      <td>23.264000</td>
      <td>30.554000</td>
      <td>14.022500</td>
    </tr>
    <tr>
      <td>std</td>
      <td>85.854236</td>
      <td>14.846809</td>
      <td>21.778621</td>
      <td>5.217457</td>
    </tr>
    <tr>
      <td>min</td>
      <td>0.700000</td>
      <td>0.000000</td>
      <td>0.300000</td>
      <td>1.600000</td>
    </tr>
    <tr>
      <td>25%</td>
      <td>74.375000</td>
      <td>9.975000</td>
      <td>12.750000</td>
      <td>10.375000</td>
    </tr>
    <tr>
      <td>50%</td>
      <td>149.750000</td>
      <td>22.900000</td>
      <td>25.750000</td>
      <td>12.900000</td>
    </tr>
    <tr>
      <td>75%</td>
      <td>218.825000</td>
      <td>36.525000</td>
      <td>45.100000</td>
      <td>17.400000</td>
    </tr>
    <tr>
      <td>max</td>
      <td>296.400000</td>
      <td>49.600000</td>
      <td>114.000000</td>
      <td>27.000000</td>
    </tr>
  </tbody>
</table>
</div>

<pre><code class="python">tv = np.array(df['TV'])
radio = np.array(df['Radio'])
newspaper = np.array(df['Newspaper'])
sales = np.array(df['Sales'])

</code></pre>

<pre><code class="python"># Get Variance and Covariance - What can we infer?
df.cov()
</code></pre>

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>TV</th>
      <th>Radio</th>
      <th>Newspaper</th>
      <th>Sales</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>TV</td>
      <td>7370.949893</td>
      <td>69.862492</td>
      <td>105.919452</td>
      <td>350.390195</td>
    </tr>
    <tr>
      <td>Radio</td>
      <td>69.862492</td>
      <td>220.427743</td>
      <td>114.496979</td>
      <td>44.635688</td>
    </tr>
    <tr>
      <td>Newspaper</td>
      <td>105.919452</td>
      <td>114.496979</td>
      <td>474.308326</td>
      <td>25.941392</td>
    </tr>
    <tr>
      <td>Sales</td>
      <td>350.390195</td>
      <td>44.635688</td>
      <td>25.941392</td>
      <td>27.221853</td>
    </tr>
  </tbody>
</table>
</div>

<pre><code class="python"># Get Correlation Coefficient - What can we infer?
df.corr(method ='pearson') 
</code></pre>

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>TV</th>
      <th>Radio</th>
      <th>Newspaper</th>
      <th>Sales</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>TV</td>
      <td>1.000000</td>
      <td>0.054809</td>
      <td>0.056648</td>
      <td>0.782224</td>
    </tr>
    <tr>
      <td>Radio</td>
      <td>0.054809</td>
      <td>1.000000</td>
      <td>0.354104</td>
      <td>0.576223</td>
    </tr>
    <tr>
      <td>Newspaper</td>
      <td>0.056648</td>
      <td>0.354104</td>
      <td>1.000000</td>
      <td>0.228299</td>
    </tr>
    <tr>
      <td>Sales</td>
      <td>0.782224</td>
      <td>0.576223</td>
      <td>0.228299</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>

<pre><code class="python"># Answer the first question: Can TV advertising spending predict the number of sales for the product?
import statsmodels.formula.api as smf

# Initialise and fit linear regression model using `statsmodels`
model = smf.ols('Sales ~ TV', data=df)
model = model.fit()
print(model.params)
</code></pre>

<pre><code>Intercept    7.032594
TV           0.047537
dtype: float64
</code></pre>
<pre><code class="python"># Predict values
TV_pred = model.predict()

# Plot regression against actual data - What do we see?
plt.figure(figsize=(12, 6))
plt.plot(df['TV'], df['Sales'], 'o')           # scatter plot showing actual data
plt.plot(df['TV'], TV_pred, 'r', linewidth=2)   # regression line
plt.xlabel('TV advertising spending')
plt.ylabel('Sales')
plt.title('Predicting with TV spendings only')

plt.show()
</code></pre>

<p><img alt="png" src="output_38_0.png" /></p>
<pre><code class="python"># Answer the second question: Can Radio advertising spending predict the number of sales for the product?
import statsmodels.formula.api as smf

# Initialise and fit linear regression model using `statsmodels`
model = smf.ols('Sales ~ Radio', data=df)
model = model.fit()
print(model.params)
</code></pre>

<pre><code>Intercept    9.311638
Radio        0.202496
dtype: float64
</code></pre>
<pre><code class="python"># Predict values
RADIO_pred = model.predict()

# Plot regression against actual data - What do we see?
plt.figure(figsize=(12, 6))
plt.plot(df['Radio'], df['Sales'], 'o')           # scatter plot showing actual data
plt.plot(df['Radio'], RADIO_pred, 'r', linewidth=2)   # regression line
plt.xlabel('Radio advertising spending')
plt.ylabel('Sales')
plt.title('Predicting with Radio spendings only')

plt.show()
</code></pre>

<p><img alt="png" src="output_40_0.png" /></p>
<pre><code class="python"># Answer the third question: Can Newspaper advertising spending predict the number of sales for the product?
import statsmodels.formula.api as smf

# Initialise and fit linear regression model using `statsmodels`
model = smf.ols('Sales ~ Newspaper', data=df)
model = model.fit()
print(model.params)
</code></pre>

<pre><code>Intercept    12.351407
Newspaper     0.054693
dtype: float64
</code></pre>
<pre><code class="python"># Predict values
NP_pred = model.predict()

# Plot regression against actual data - What do we see?
plt.figure(figsize=(12, 6))
plt.plot(df['Newspaper'], df['Sales'], 'o')           # scatter plot showing actual data
plt.plot(df['Newspaper'], NP_pred, 'r', linewidth=2)   # regression line
plt.xlabel('Newspaper advertising spending')
plt.ylabel('Sales')
plt.title('Predicting with Newspaper spendings only')

plt.show()
</code></pre>

<p><img alt="png" src="output_42_0.png" /></p>
<pre><code class="python"># Answer the fourth question: Can we use the three of them to predict the number of sales for the product?
# This is a case of multiple linear regression model. This is simply a linear regression model with more than one predictor:
# and is modelled by:  Y‚Çë = Œ± + Œ≤‚ÇÅX‚ÇÅ + Œ≤‚ÇÇX‚ÇÇ + ‚Ä¶ + Œ≤‚ÇöX‚Çö , where p is the number of predictors.
# In this case: Sales = Œ± + Œ≤1*TV + Œ≤2*Radio + Œ≤3*Newspaper
# Multiple Linear Regression with scikit-learn:
from sklearn.linear_model import LinearRegression

# Build linear regression model using TV,Radio and Newspaper as predictors
# Split data into predictors X and output Y
predictors = ['TV', 'Radio', 'Newspaper']
X = df[predictors]
y = df['Sales']

# Initialise and fit model
lm = LinearRegression()
model = lm.fit(X, y)
</code></pre>

<pre><code class="python">print(f'alpha = {model.intercept_}')
print(f'betas = {model.coef_}')
</code></pre>

<pre><code>alpha = 2.9388893694594085
betas = [ 0.04576465  0.18853002 -0.00103749]
</code></pre>
<pre><code class="python"># Therefore, our model can be written as:
#Sales = 2.938 + 0.046*TV + 0.1885*Radio -0.001*Newspaper
# we can predict sales from any combination of TV and Radio and Newspaper advertising costs! 
#For example, if we wanted to know how many sales we would make if we invested 
# $300 in TV advertising and $200 in Radio advertising and $50 in Newspaper advertising
#all we have to do is plug in the values:
new_X = [[300, 200,50]]
print(model.predict(new_X))
</code></pre>

<pre><code>[54.32241174]
</code></pre>
<pre><code class="python"># Answer the final question : Which parameter is a better predictor of the number of sales for the product?
# How can we answer that?
# WHAT CAN WE INFER FROM THE BETAs ?

</code></pre>

<hr />
<h4 id="so-far-on-linear-regression">So far on linear regression ... <br></h4>
<p><img alt="" src="https://memegenerator.net/img/instances/73698591.jpg" /> <br></p>
<ul>
<li><strong>What is linear regression?</strong><br>
    a basic predictive analytics technique that uses historical data to predict an output variable.<br></li>
<li><strong>Why do we need linear regression?</strong>
    To explore the relationship between predictor and output variables and predict the output variable based on known values of predictors.  <br>    </li>
<li><strong>How does linear regression work?</strong>
    To estimate Y using linear regression, we assume the equation:  ùëåùëí=Œ≤ùëã+Œ± <br>
    Our goal is to find statistically significant values of the parameters Œ± and Œ≤ that minimise the difference between Y and Y‚Çë. If we are able to determine the optimum values of these two parameters, then we will have the line of best fit that we can use to predict the values of Y, given the value of X. <br></li>
<li><strong>How to estimate the coefficients?</strong>
    We used a method called "Ordinary Least Squares (OLS)". <strong>But that is not the only way. Let's put a pin on that!</strong></li>
</ul>
<p><img alt="" src="https://media3.giphy.com/media/15bf6pru8mSR2/giphy.gif" /> <br></p>
<h4 id="remember-when-we-discussed-probability-density-function-pdf-for-the-normal-distribution-probably-not">Remember when we discussed Probability Density Function (PDF) for the normal distribution? - Probably not!<br></h4>
<p><img alt="" src="https://miro.medium.com/max/572/1*P78bMZPhhKnzLkwcNgeJ0g.png" /> <br></p>
<h4 id="this-equation-is-telling-us-the-probability-our-sample-x-from-our-random-variable-x-when-the-true-parameters-of-the-distribution-are-and">This equation is telling us the probability our sample x from our random variable X, when the true parameters of the distribution are Œº and œÉ. <br></h4>
<h3 id="example1-lets-say-our-sample-is-3-what-is-the-probability-it-comes-from-a-distribution-of-3-and-1-what-if-it-came-from-a-distribution-with-7-and-2-which-one-is-more-probable">Example1 :Let‚Äôs say our sample is 3, what is the probability it comes from a distribution of Œº = 3 and œÉ = 1? What if it came from a distribution with Œº = 7 and œÉ = 2? Which one is more probable?<br></h3>
<pre><code class="python">import numpy as np
import pandas as pd
import statistics
import scipy.stats
from matplotlib import pyplot as plt
</code></pre>

<pre><code class="python">scipy.stats.norm.pdf(3, 3, 1)
</code></pre>

<pre><code>0.3989422804014327
</code></pre>
<pre><code class="python">scipy.stats.norm.pdf(3, 7, 2)
</code></pre>

<pre><code>0.02699548325659403
</code></pre>
<h4 id="so-it-is-much-more-likely-it-came-from-the-first-distribution-the-pdf-equation-has-shown-us-how-likely-those-values-are-to-appear-in-a-distribution-with-certain-parameters-keep-that-in-mind-for-later-but-what-if-we-had-a-bunch-of-points-we-wanted-to-estimate">So it is much more likely it came from the first distribution. The PDF equation has shown us how likely those values are to appear in a distribution with certain parameters. Keep that in mind for later. But what if we had a bunch of points we wanted to estimate?</h4>
<h4 id="lets-assume-we-get-a-bunch-of-samples-fromx-which-we-know-to-come-from-some-normal-distribution-and-all-are-mutually-independent-from-each-other-if-this-is-the-case-the-total-probability-of-observing-all-of-the-data-is-the-product-of-obtaining-each-data-point-individually">Let‚Äôs assume we get a bunch of samples fromX which we know to come from some normal distribution, and all are mutually independent from each other. If this is the case, the total probability of observing all of the data is the product of obtaining each data point individually.</h4>
<h4 id="this-should-kinda-remind-you-of-our-class-on-probability-where-we-talked-about-the-probability-of-multiple-events-happening-back-to-back-eg-the-royal-flush-set">This should kinda remind you of our class on probability, where we talked about the probability of multiple events happening back to back (e.g., the royal flush set).</h4>
<h3 id="example2-what-is-the-probability-of-2-and-6-being-drawn-from-a-distribution-with-4-and-1">Example2 : What is the probability of 2 and 6 being drawn from a distribution with Œº = 4 and œÉ = 1<br></h3>
<pre><code class="python">scipy.stats.norm.pdf(2, 4, 1) * scipy.stats.norm.pdf(6, 4, 1)
</code></pre>

<pre><code>0.0029150244650281948
</code></pre>
<h4 id="maximum-likelihood-estimation-mle-is-used-to-specify-a-distribution-of-unknown-parameters-then-using-your-data-to-pull-out-the-actual-parameter-valuesto-go-back-to-the-pin-lets-look-at-our-linear-model">Maximum Likelihood Estimation (MLE) is used to specify a distribution of unknown parameters, then using your data to pull out the actual parameter values.To go back to the pin!, let's look at our linear model:</h4>
<p><img alt="" src="https://miro.medium.com/max/352/1*iJrwssQh4dJARzeuQPw1kw.png" /> <br></p>
<h4 id="the-noise-parameter-error-is-basically-why-the-points-samples-do-not-fall-exactly-on-the-line-the-error-for-each-point-would-be-the-distance-from-the-point-to-our-line-wed-like-to-explicitly-include-those-errors-in-our-model-one-method-of-doing-this-is-to-assume-the-errors-are-distributed-from-a-gaussian-distribution-with-a-mean-of-0-and-some-unknown-variance-2-the-gaussian-seems-like-a-good-choice-because-our-errors-look-like-theyre-symmetric-about-were-the-line-would-be-and-that-small-errors-are-more-likely-than-large-errors">The noise parameter (error) is basically why the points (samples) do not fall exactly on the line. The error for each point would be the distance from the point to our line. We‚Äôd like to explicitly include those errors in our model. One method of doing this, is to assume the errors are distributed from a Gaussian distribution with a mean of 0 and some unknown variance œÉ¬≤. The Gaussian seems like a good choice, because our errors look like they‚Äôre symmetric about were the line would be, and that small errors are more likely than large errors. <br></h4>
<h4 id="this-model-has-three-parameters-the-slope-and-intercept-of-our-line-and-the-variance-of-the-noise-distribution-our-main-goal-is-to-find-the-best-parameters-for-the-slope-and-intercept-of-our-line">This model has three parameters: the slope and intercept of our line and the variance of the noise distribution. Our main goal is to find the best parameters for the slope and intercept of our line.</h4>
<h4 id="lets-rewrite-our-model-from-above-as-a-single-conditional-distribution-given-x">let‚Äôs rewrite our model from above as a single conditional distribution given x:</h4>
<p><img alt="" src="https://miro.medium.com/max/403/1*S9Wo7Ay3O-CGarsNULSWOA.png" /> <br></p>
<h4 id="this-is-equivalent-to-pushing-our-x-through-the-equation-of-the-line-and-then-adding-noise-from-the-0-mean-gaussian-now-we-can-write-the-conditional-distribution-of-y-given-x-in-terms-of-this-gaussian-this-is-just-the-equation-of-a-gaussian-distributions-probability-density-function-with-our-linear-equation-in-place-of-the-mean">This is equivalent to pushing our x through the equation of the line and then adding noise from the 0 mean Gaussian. Now, we can write the conditional distribution of y given x in terms of this Gaussian. This is just the equation of a Gaussian distribution‚Äôs probability density function, with our linear equation in place of the mean:</h4>
<p><img alt="" src="https://miro.medium.com/max/576/1*3M7mJamXgcFPXzvD0U4yIA.png" /> <br></p>
<h4 id="the-semicolon-in-the-conditional-distribution-acts-just-like-a-comma-but-its-a-useful-notation-for-separating-our-observed-data-from-the-parameters">The semicolon in the conditional distribution acts just like a comma, but it‚Äôs a useful notation for separating our observed data from the parameters. <br></h4>
<h4 id="each-point-is-independent-and-identically-distributed-iid-so-we-can-write-the-likelihood-function-with-respect-to-all-of-our-observed-points-as-the-product-of-each-individual-probability-density-since-2-is-the-same-for-each-data-point-we-can-factor-out-the-term-of-the-gaussian-which-doesnt-include-x-or-y-from-the-product">Each point is independent and identically distributed (iid), so we can write the likelihood function with respect to all of our observed points as the product of each individual probability density. Since œÉ¬≤ is the same for each data point, we can factor out the term of the Gaussian which doesn‚Äôt include x or y from the product:</h4>
<p><img alt="" src="https://miro.medium.com/max/576/1*JXtvd6fO6ydgAqQR4jAaWQ.png" /> <br></p>
<h4 id="the-next-step-in-mle-is-to-find-the-parameters-which-maximize-this-function-to-make-our-equation-simpler-lets-take-the-log-of-our-likelihood-recall-that-maximizing-the-log-likelihood-is-the-same-as-maximizing-the-likelihood-since-the-log-is-monotonic-the-natural-log-cancels-out-with-the-exponential-turns-products-into-sums-of-logs-and-division-into-subtraction-of-logs-so-our-log-likelihood-looks-much-simpler">The next step in MLE, is to find the parameters which maximize this function. To make our equation simpler, let‚Äôs take the log of our likelihood. Recall, that maximizing the log-likelihood is the same as maximizing the likelihood since the log is monotonic. The natural log cancels out with the exponential, turns products into sums of logs, and division into subtraction of logs; so our log-likelihood looks much simpler:</h4>
<p><img alt="" src="https://miro.medium.com/max/576/1*gDNxsKgiWTj6AWmolmkjlQ.png" /> <br></p>
<h4 id="to-clean-things-up-a-bit-more-lets-write-the-output-of-our-line-as-a-single-value">To clean things up a bit more, let‚Äôs write the output of our line as a single value:</h4>
<p><img alt="" src="https://miro.medium.com/max/226/1*tCAZf5pWI5UYyWLXiZ-tSw.png" /> <br></p>
<h4 id="now-our-log-likelihood-can-be-written-as">Now our log-likelihood can be written as::</h4>
<p><img alt="" src="https://miro.medium.com/max/576/1*U8yya-GV548dLYdRVabERQ.png" /> <br></p>
<h4 id="to-remove-the-negative-signs-lets-recall-that-maximizing-a-number-is-the-same-thing-as-minimizing-the-negative-of-the-number-so-instead-of-maximizing-the-likelihood-lets-minimize-the-negative-log-likelihood">To remove the negative signs, let‚Äôs recall that maximizing a number is the same thing as minimizing the negative of the number. So instead of maximizing the likelihood, let‚Äôs minimize the negative log-likelihood:</h4>
<p><img alt="" src="https://miro.medium.com/max/576/1*Y_B6FPJq0jb17qK04MVltw.png" /> <br></p>
<h4 id="our-ultimate-goal-is-to-find-the-parameters-of-our-line-to-minimize-the-negative-log-likelihood-with-respect-to-the-linear-parameters-the-s-we-can-imagine-that-our-variance-term-is-a-fixed-constant-removing-any-constants-which-dont-include-our-s-wont-alter-the-solution-therefore-we-can-throw-out-any-constant-terms-and-elegantly-write-what-were-trying-to-minimize-as">Our ultimate goal is to find the parameters of our line. To minimize the negative log-likelihood with respect to the linear parameters (the Œ∏s), we can imagine that our variance term is a fixed constant. Removing any constant‚Äôs which don‚Äôt include our Œ∏s won‚Äôt alter the solution. Therefore, we can throw out any constant terms and elegantly write what we‚Äôre trying to minimize as:</h4>
<p><img alt="" src="https://miro.medium.com/max/175/1*O8b2CNiqn3xjUF3fkklrXQ.png" /> <br></p>
<h4 id="the-maximum-likelihood-estimate-for-our-linear-model-is-the-line-which-minimizes-the-sum-of-squared-errors">The maximum likelihood estimate for our linear model is the line which minimizes the sum of squared errors!</h4>
<p><img alt="" src="https://media1.giphy.com/media/SJX3gbZ2dbaEhU92Pu/source.gif" /> <br></p>
<h4 id="now-lets-solve-for-parameters-weve-concluded-that-the-maximum-likelihood-estimates-for-our-slope-and-intercept-can-be-found-by-minimizing-the-sum-of-squared-errors-lets-expand-out-our-minimization-objective-and-use-i-as-our-index-over-our-n-data-points">Now, let's solve for parameters. We‚Äôve concluded that the maximum likelihood estimates for our slope and intercept can be found by minimizing the sum of squared errors. Let‚Äôs expand out our minimization objective and use i as our index over our n data points:</h4>
<p><img alt="" src="https://miro.medium.com/max/403/1*0zO8-m3ZdruX0hgJ4zLm9g.png" /> <br></p>
<h4 id="the-square-in-the-sse-formula-makes-it-quadratic-with-a-single-minimum-the-minimum-can-be-found-by-taking-the-derivative-with-respect-to-each-of-the-parameters-setting-it-equal-to-0-and-solving-for-the-parameters-in-turn">The square in the SSE formula makes it quadratic with a single minimum. The minimum can be found by taking the derivative with respect to each of the parameters, setting it equal to 0, and solving for the parameters in turn. <br></h4>
<h4 id="taking-the-partial-derivative-with-respect-to-the-intercept-setting-the-derivative-equal-to-0-and-solving-for-the-intercept-gives-us">Taking the partial derivative with respect to the intercept, Setting the derivative equal to 0 and solving for the intercept gives us:</h4>
<p><img alt="" src="https://miro.medium.com/max/227/1*YzIf9e2kTWbjgx58wb-KXw.png" /> <br></p>
<h4 id="taking-the-partial-derivative-with-respect-to-the-slope-setting-the-derivative-equal-to-0-and-solving-for-the-slope-gives-us">Taking the partial derivative with respect to the slope, Setting the derivative equal to 0 and solving for the slope gives us:</h4>
<p><img alt="" src="https://miro.medium.com/max/324/1*o0vOZ25b1h57UyidKsJlvQ.png" /> <br></p>
<h4 id="and-now-its-time-to-put-it-all-together">And now it's time to put it all together:</h4>
<pre><code class="python">def find_line(xs, ys):
    &quot;&quot;&quot;Calculates the slope and intercept&quot;&quot;&quot;

    # number of points
    n = len(xs)
    # calculate means
    x_bar = sum(xs)/n
    y_bar = sum(ys)/n

    # calculate slope
    num = 0
    denom = 0
    for i in range(n):
        num += (xs[i]-x_bar)*(ys[i]-y_bar)
        denom += (xs[i]-x_bar)**2
    slope = num/denom

    # calculate intercept
    intercept = y_bar - slope*x_bar

    return slope, intercept
</code></pre>

<h3 id="example-lets-have-a-look-at-the-familiar-problem-from-exam-ii-which-was-also-an-example-in-the-previous-lab">Example: Let's have a look at the familiar problem  from Exam II which was also an Example in the previous lab!<br></h3>
<h4 id="we-had-a-table-of-recorded-times-and-speeds-from-some-experimental-observations-use-mle-to-find-the-intercept-and-the-slope">We had a table of recorded times and speeds from some experimental observations. Use MLE to find the intercept and the slope:</h4>
<table>
<thead>
<tr>
<th align="right">Elapsed Time (s)</th>
<th align="right">Speed (m/s)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr>
<td align="right">1.0</td>
<td align="right">3</td>
</tr>
<tr>
<td align="right">2.0</td>
<td align="right">7</td>
</tr>
<tr>
<td align="right">3.0</td>
<td align="right">12</td>
</tr>
<tr>
<td align="right">4.0</td>
<td align="right">20</td>
</tr>
<tr>
<td align="right">5.0</td>
<td align="right">30</td>
</tr>
<tr>
<td align="right">6.0</td>
<td align="right">45.6</td>
</tr>
<tr>
<td align="right">7.0</td>
<td align="right">60.3</td>
</tr>
<tr>
<td align="right">8.0</td>
<td align="right">77.7</td>
</tr>
<tr>
<td align="right">9.0</td>
<td align="right">97.3</td>
</tr>
<tr>
<td align="right">10.0</td>
<td align="right">121.1</td>
</tr>
</tbody>
</table>
<pre><code class="python">time = [0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]
speed = [0, 3, 7, 12, 20, 30, 45.6, 60.3, 77.7, 97.3, 121.2]
find_line(time, speed) #Is this similar to our past results?! 
</code></pre>

<pre><code>(11.977272727272727, -16.78636363636364)
</code></pre>
<pre><code class="python"># Predict values
X = np.array(time)
alpha = -16.78636363636364
beta = 11.977272727272727
ypred = alpha + beta * X


# Plot regression against actual data
plt.figure(figsize=(12, 6))
plt.plot(X, speed, 'o')           # scatter plot showing actual data
plt.plot(X, ypred, 'r', linewidth=2)   # regression line
plt.xlabel('Time (s)')
plt.ylabel('Speed (m/s)')
plt.title('model vs observed')

plt.show()
</code></pre>

<p><img alt="png" src="output_60_0.png" /></p>
<h2 id="goodness-of-fit">Goodness-of-Fit <br></h2>
<h3 id="so-far-we-have-assessed-the-quality-of-fits-visually-we-can-make-numerical-assessments-as-well-via-goodness-of-fit-gof-measures-lets-discuss-three-of-the-most-common-metrics-for-evaluating-predictions-on-regression-machine-learning-problems">So far, we have assessed the quality of fits visually. We can make numerical assessments as well via Goodness-of-Fit (GOF) measures. Let's discuss three of the most common metrics for evaluating predictions on regression machine learning problems: <br></h3>
<h3 id="mean-absolute-error-mae">Mean Absolute Error (MAE): <br></h3>
<pre><code>The Mean Absolute Error (or MAE) is the average of the absolute differences between predictions and actual values. It gives an idea of how wrong the predictions were. The measure gives an idea of the magnitude of the error, but no idea of the direction (e.g. over or under predicting). Here is the formula:
</code></pre>
<p><img alt="" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/3ef87b78a9af65e308cf4aa9acf6f203efbdeded" /> <br></p>
<pre><code>It is thus an arithmetic average of the absolute errors |ei|=|yi-xi|, where yi is the prediction and xi the true value.  This is known as a scale-dependent accuracy measure and therefore cannot be used to make comparisons between series using different scales.
</code></pre>
<pre><code class="python"># calculate manually
d = speed - ypred
mae_m = np.mean(abs(d))


print(&quot;Results by manual calculation:&quot;)
print(&quot;MAE:&quot;,mae_m)



import sklearn.metrics as metrics
mae = metrics.mean_absolute_error(speed, ypred)
print(mae)
</code></pre>

<pre><code>Results by manual calculation:
MAE: 8.927272727272728
8.927272727272728
</code></pre>
<h3 id="mean-squared-error-mse-and-root-mean-squared-error-rmse">Mean Squared Error (MSE) and Root Mean Squared Error (RMSE): <br></h3>
<pre><code>The Mean Squared Error (or MSE) is much like the mean absolute error in that it provides a gross idea of the magnitude of error. It measures the average of the squares of the errors‚Äîthat is, the average squared difference between the estimated values and the actual value. The MSE is a measure of the quality of an estimator‚Äîit is always non-negative, and values closer to zero are better. An MSE of zero, meaning that the estimator predicts observations of the parameter with perfect accuracy, is ideal (but typically not possible).Taking the square root of the mean squared error converts the units back to the original units of the output variable and can be meaningful for description and presentation. This is called the Root Mean Squared Error (or RMSE). RMSE is the most widely used metric for regression tasksHere is the formula:
</code></pre>
<p><img alt="" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e258221518869aa1c6561bb75b99476c4734108e" /> <br></p>
<pre><code class="python">mse_m = np.mean(d**2)
rmse_m = np.sqrt(mse_m)
print(&quot;MSE:&quot;, mse_m)
print(&quot;RMSE:&quot;, rmse_m)
mse = metrics.mean_squared_error(speed, ypred)
rmse = np.sqrt(mse) # or mse**(0.5) 
print(mse)
print(rmse)
</code></pre>

<pre><code>MSE: 108.88210743801659
RMSE: 10.434658951686758
108.88210743801659
10.434658951686758
</code></pre>
<h3 id="r2-metric">R^2 Metric: <br></h3>
<pre><code>The R^2 (or R Squared) metric provides an indication of the goodness of fit of a set of predictions to the actual values. In statistical literature, this measure is called the coefficient of determination. This is a value between 0 and 1 for no-fit and perfect fit respectively. It provides a measure of how well observed outcomes are replicated by the model, based on the proportion of total variation of outcomes explained by the model..Here is the formula:
</code></pre>
<p><img alt="" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/3a1f55d7e84c24299917fb3fec4d0439b81e728d" /> <br>
<img alt="" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/2669c9340581d55b274d3b8ea67a7deb2225510b" /> <br>
<img alt="" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c7e3ab84636f38c257641f85f009bcb422c73151" /> <br></p>
<pre><code class="python">r2_m = 1-(sum(d**2)/sum((speed-np.mean(speed))**2))
print(&quot;R-Squared:&quot;, r2_m)
r2 = metrics.r2_score(speed, ypred)
print(r2)
</code></pre>

<pre><code>R-Squared: 0.9294545816516323
0.9294545816516323
</code></pre>
<p><img alt="" src="https://media2.giphy.com/media/5nj4ZZWl6QwneEaBX4/source.gif" /> <br></p>
<p><em>This notebook was inspired by several blogposts including:</em>
- <strong>"Introduction to Linear Regression in Python"</strong> by <strong>Lorraine Li</strong> available at<em> https://towardsdatascience.com/introduction-to-linear-regression-in-python-c12a072bedf0 <br>
- <strong>"In Depth: Linear Regression"</strong> available at</em> https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html <br>
- <strong>"A friendly introduction to linear regression (using Python)"</strong> available at<em> https://www.dataschool.io/linear-regression-in-python/ <br>
- <strong>"What is Maximum Likelihood Estimation ‚Äî Examples in Python"</strong> by <strong>Robert R.F. DeFilippi</strong> available at</em> https://medium.com/@rrfd/what-is-maximum-likelihood-estimation-examples-in-python-791153818030 <br>
- <strong>"Linear Regression"</strong> by <strong>William Fleshman</strong>  available at<em> https://towardsdatascience.com/linear-regression-91eeae7d6a2e <br>
- <strong>"Regression Accuracy Check in Python (MAE, MSE, RMSE, R-Squared)"</strong> available at</em> https://www.datatechnotes.com/2019/10/accuracy-check-in-python-mae-mse-rmse-r.html <br></p>
<p><em>Here are some great reads on these topics:</em> 
- <strong>"Linear Regression in Python"</strong> by <strong>Sadrach Pierre</strong> available at<em> https://towardsdatascience.com/linear-regression-in-python-a1d8c13f3242 <br>
- <strong>"Introduction to Linear Regression in Python"</strong> available at</em> https://cmdlinetips.com/2019/09/introduction-to-linear-regression-in-python/ <br>
- <strong>"Linear Regression in Python"</strong> by <strong>Mirko Stojiljkoviƒá</strong> available at<em> https://realpython.com/linear-regression-in-python/ <br>
- <strong>"A Gentle Introduction to Linear Regression With Maximum Likelihood Estimation"</strong> by <strong>Jason Brownlee</strong> available at</em> https://machinelearningmastery.com/linear-regression-with-maximum-likelihood-estimation/ <br>
- <strong>"Metrics To Evaluate Machine Learning Algorithms in Python"</strong> by <strong>Jason Brownlee</strong> available at<em> https://machinelearningmastery.com/metrics-evaluate-machine-learning-algorithms-python/ <br>
- <strong>"A Gentle Introduction to Maximum Likelihood Estimation"</strong> by <strong>Jonathan Balaban</strong> available at</em> https://towardsdatascience.com/a-gentle-introduction-to-maximum-likelihood-estimation-9fbff27ea12f <br>
- <strong>"Regression: An Explanation of Regression Metrics And What Can Go Wrong"</strong> by <strong>Divyanshu Mishra</strong> available at<em> https://towardsdatascience.com/regression-an-explanation-of-regression-metrics-and-what-can-go-wrong-a39a9793d914 <br>
- <strong>"Tutorial: Understanding Regression Error Metrics in Python"</strong> available at</em> https://www.dataquest.io/blog/understanding-regression-error-metrics/ <br></p>
<p><em>Here are some great videos on these topics:</em> 
- <strong>"StatQuest: Fitting a line to data, aka least squares, aka linear regression."</strong> by <strong>StatQuest with Josh Starmer</strong> available at<em> https://www.youtube.com/watch?v=PaFPbb66DxQ&amp;list=PLblh5JKOoLUIzaEkCLIUxQFjPIlapw8nU <br>
- <strong>"Statistics 101: Linear Regression, The Very Basics"</strong> by <strong>Brandon Foltz</strong> available at</em> https://www.youtube.com/watch?v=ZkjP5RJLQF4 <br>
- <strong>"How to Build a Linear Regression Model in Python | Part 1" and 2,3,4!</strong> by <strong>Sigma Coding</strong> available at<em> https://www.youtube.com/watch?v=MRm5sBfdBBQ <br>
- <strong>"StatQuest: Maximum Likelihood, clearly explained!!!"</strong> by <strong>StatQuest with Josh Starmer</strong> available at</em> https://www.youtube.com/watch?v=XepXtl9YKwc <br>
- <strong>"Maximum Likelihood for Regression Coefficients (part 1 of 3)" and part 2 and 3</strong> by <strong>Professor Knudson</strong> available at<em> https://www.youtube.com/watch?v=avs4V7wBRw0 <br>
- <strong>"StatQuest: R-squared explained"</strong> by <strong>StatQuest with Josh Starmer</strong> available at</em> https://www.youtube.com/watch?v=2AQKmw14mHM <br></p>
<hr />
<p><img alt="" src="https://media2.giphy.com/media/dNgK7Ws7y176U/200.gif" /> <br></p>
<h2 id="exercise-linear-regression-yea-or-nay">Exercise: Linear Regression - Yea or Nay <br></h2>
<h3 id="list-some-of-the-pros-and-cons-of-linear-regression">List some of the pros and cons of linear regression.</h3>
<h4 id="make-sure-to-cite-any-resources-that-you-may-use"><em>Make sure to cite any resources that you may use.</em></h4>
<pre><code class="python">
</code></pre>

<p><img alt="" src="http://quotessayings.net/pics/linear-regression-quote-by-jordan-ellenberg-244617.jpg" /></p></div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>
            var base_url = "../../..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../../../js/base.js" defer></script>
        <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" defer></script>
        <script src="../../../mathjaxhelper.js" defer></script>
        <script src="../../../search/main.js" defer></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="Search Modal" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
                <h4 class="modal-title" id="exampleModalLabel">Search</h4>
            </div>
            <div class="modal-body">
                <p>
                    From here you can search these documents. Enter
                    your search terms below.
                </p>
                <form role="form">
                    <div class="form-group">
                        <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="Keyboard Shortcuts Modal" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
                <h4 class="modal-title" id="exampleModalLabel">Keyboard Shortcuts</h4>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
